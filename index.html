<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
    <title>ManiFlow Policy</title>
    <link rel="stylesheet" href="assets/css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="icon" type="image/png" sizes="512x512" href="icon.png">
    <link rel="manifest" href="/site.webmanifest">

    <meta property="og:type" content="website"/>
    <meta property="og:image:type" content="image/png">
    <meta property="og:url" content="https://humanoid-manipulation/.github.io/"/>
    <meta property="og:title" content="ManiFlow Policy"/>
    <meta property="og:description" content="Generalizable Humanoid Manipulation with 3D Diffusion Policies"/>

    <!-- twitter card -->
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:title" content="ManiFlow Policy"/>
    <meta name="twitter:description"
          content="Generalizable Humanoid Manipulation with 3D Diffusion Policies"/>
    <meta name="twitter:creator" content="@ZeYanjie"/>

    <!-- extra metadata for Slack unfurls -->
    <!--    <meta name="twitter:label1" content="Published at"/>-->
    <!--    <meta name="twitter:data1" content="RSS 2024"/>-->
    <!--    <meta name="twitter:label2" content="Reading time"/>-->
    <!--    <meta name="twitter:data2" content="10 minutes"/>-->

    <!-- extra metadata — unknown support -->
    <meta property="og:type" content="article"/>
    <meta property="article:section" content="Research"/>
    <meta property="article:tag" content="Robotics"/>
    <meta property="article:tag" content="Machine Learning"/>

</head>
<body>

<div class="full-page-image">
    <div id="video_grid_1" class="video_grid">
        <div class="video_large_1 video_container">
            <video src="videos/teaser/h1_pouring_1.mp4" autoplay muted loop playsinline></video>
        </div>
        <div class="video_small_group_1">
            <div class="video_container">
                <video src="videos/teaser/h1_pouring_2.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/h1_pouring_3.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/h1_pouring_4.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/h1_pouring_5.mp4" autoplay muted loop playsinline></video>
            </div>
        </div>
    </div>
    
    <div id="video_grid_2" class="video_grid">
        <div class="video_small_group_2">
            <div class="video_container">
                <video src="videos/teaser/h1_grsaping_5.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/h1_grsaping_2.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/h1_grsaping_3.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/h1_grsaping_4.mp4" autoplay muted loop playsinline></video>
            </div>
        </div>
        <div class="video_large_2 video_container">
            <video src="videos/teaser/h1_grsaping_1.mp4" autoplay muted loop playsinline></video>
        </div>
    </div>

    <div id="video_grid_1" class="video_grid">
        <div class="video_large_1 video_container">
            <video src="videos/teaser/bunny_stack_1.mp4" autoplay muted loop playsinline></video>
        </div>
        <div class="video_small_group_1">
            <div class="video_container">
                <video src="videos/teaser/bunny_grasp_1.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/bunny_handover_6.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/bunny_pouring_1.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/bunny_grasp_2.mp4" autoplay muted loop playsinline></video>
            </div>
        </div>
    </div>


    <div id="video_grid_2" class="video_grid">
        <div class="video_small_group_2">
            <div class="video_container">
                <video src="videos/teaser/bunny_sorting_2.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/bunny_handover_2.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/bunny_pouring_2.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/bunny_grasp_4.mp4" autoplay muted loop playsinline></video>
            </div>
        </div>
        <div class="video_large_2 video_container">
            <video src="videos/teaser/bunny_sorting_1.mp4" autoplay muted loop playsinline></video>
        </div>
    </div>


    <!-- <div id="video_grid_1" class="video_grid">

        <div class="video_large_1 video_container">
            <video src="videos/teaser/23pour.mp4" autoplay muted loop playsinline></video>
        </div>
        <div class="video_small_group_1">
            <div class="video_container">
                <video src="videos/teaser/20wipe.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/12pour.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/21grasp.mp4" autoplay muted loop playsinline></video>
            </div>
            <div class="video_container">
                <video src="videos/teaser/20pour.mp4" autoplay muted loop playsinline></video>
            </div>
        </div>
    </div> -->

     <!-- <div class="overlay"></div> -->
    <div class="content" style="padding: 0 0vh">
        <h1>ManiFlow: A Dexterous Manipulation Policy using Flow Matching</h1>
        <!-- <p>With data from only one scene, our humanoid robot automonously performs skills in the wild open world. All skills in videos are autonomous. Videos are 4x speed.</p> -->
    </div>

</div>


<div class="title_left">
    <h1>
        ManiFlow: A Dexterous Manipulation Policy <br> using Flow Matching
    </h1>
    <div class="author-container">
        <div class="author-name"><a href="https://geyan21.github.io/" target="_blank">Ge Yan<sup>1</sup></a></div>
        <div class="author-name"><a href="https://jiyuezh.github.io/" target="_blank">Jiyue Zhu*<sup>2</sup></a></div>
        <div class="author-name"><a href="https://www.linkedin.com/in/yuquand/" target="_blank">Yuquan Deng*<sup>1</sup></a></div>
    </div>
    <div class="author-container">
        <div class="author-name"><a href="https://aaronyang1223.github.io/" target="_blank">Shiqi Yang<sup>2</sup></a></div>
        <div class="author-name"><a href="https://rogerqi.github.io/" target="_blank">Ri-Zhao Qiu<sup>2</sup></a></div>
        <div class="author-name"><a href="https://chengxuxin.github.io/" target="_blank">Xuxin Cheng<sup>2</sup></a></div>
        <div class="author-name"><a href="https://memmelma.github.io/" target="_blank">Marius Memmel<sup>1</sup></a></div>
    </div>
    <div class="author-container">
        <div class="author-name"><a href="https://ranjaykrishna.com/index.html" target="_blank">Ranjay Krishna<sup>1</sup></a></div>    
        <div class="author-name"><a href="https://imankgoyal.github.io/" target="_blank">Ankit Goyal<sup>3</sup></a></div>
        <div class="author-name"><a href="https://xiaolonw.github.io/" target="_blank">Xiaolong Wang<sup>2</sup></a></div>
        <div class="author-name"><a href="https://homes.cs.washington.edu/~fox/" target="_blank">Dieter Fox<sup>1,3</sup></a></div>
    </div>
    <div class="affiliation">
        <p><sup>1</sup>University of Washington&nbsp;<sup>2</sup>University of California San Diego
            &nbsp; <sup>3</sup>Nvidia
        </p>
    </div>
    <div class="button-container">
        <a href="https://arxiv.org/abs/2410.10803" target="_blank" class="button"><i class="ai ai-arxiv"></i>&emsp14;arXiv</a>
        <a href="assets/paper.pdf" target="_blank" class="button"><i class="fa-light fa-file"></i>&emsp14;PDF</a>
        <a href="https://github.com/YanjieZe/Improved-3D-Diffusion-Policy" target="_blank" class="button_large"><i
            class="fa fa-github"></i>&emsp14;Code (Learning)</a>
            <a href="https://github.com/YanjieZe/Humanoid-Teleoperation" target="_blank" class="button_large"><i
                class="fa fa-github"></i>&emsp14;Code (Teleop)</a>
        <a href="https://x.com/ZeYanjie/status/1846024050067538399" target="_blank" class="button"><i class="fa-brands fa-x-twitter"></i>&emsp14;TL;DR</a>
        <a href="https://youtu.be/6H2MkMetmFk" target="_blank" class="button"><i class="fa-brands fa-youtube"></i>&emsp14;YouTube</a>
    </div>
    <!--        <div class="venue">-->
    <!--            <p>-->
    <!--                <b>Robotics: Science and Systems (RSS) 2024</b>-->
    <!--            </p>-->
    <!--        </div>-->
    
    


    <br>


    <div id="abstract">
        <h1>Abstract</h1>
        <p>
            Generative models based on flow matching offer significant potential for learning robot policies, particularly in generating high-dimensional, dexterous behaviors that are conditioned on diverse observations. 
            In this work, we introduce ManiFlow, an advanced flow matching model specifically designed to support dexterous manipulation tasks. 
            ManiFlow improves over flow matching both in the learning procedure and in the model architecture, resulting in better robustness and efficacy. 
            ManiFlow consistently exhibits strong generalization capabilities, outperforming existing state-of-the-art robot learning methods on a wide range of benchmarks. 
            We also demonstrate the powerful capabilities of ManiFlow in solving complex bimanual dexterous manipulation challenges.
            
        </p>
        <br>
        <!-- <div class="publication-video">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/6H2MkMetmFk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
          </div> -->
            <!-- <div class="video_container">
                <video loop autoplay muted playsinline preload="metadata">
                    <source src="videos/short_teaser.mp4" type="video/mp4">
                </video>
            </div> -->
    </div>
</div>

<hr class="rounded">





<div id="overview">

    <!-- <h1>Summary</h1>
    <div class="allegrofail">
        <div class="video_container">
            <div class="publication-video">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/tD6hP_skZtE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
    </div> -->

    <h1>Overview of ManiFlow</h1>
    <p>
        ManiFlow is a visual imitation learning algorithm for dexterous robotic manipulation using Flow Matching with a consistency training objective, enabling efficient learning of high-dimensional dexterous behavior. 
        Our comprehensive evaluation spanning over 60 simulation tasks and eight real-world scenarios demonstrates ManiFlow’s effectiveness, 
        particularly in challenging real-world bimanual dexterous manipulation across three different robot platforms, including Franka, bimanual Ability hands and Unitree H1 humanoid robot with Inspire hands, 
        where it achieves a 98.3% improvement over existing approaches in real-world. 
        These results establish ManiFlow as a promising foundation for complex robotic manipulation tasks.
    </p>
    <div class="allegrofail">
        <div class="video_container">
            <video loop autoplay muted playsinline preload="metadata">
                <source src="videos/overview.mp4" type="video/mp4">
            </video>
        </div>
    </div>


    <hr class="rounded">

    
    <!-- <h1>Whole-Upper-Body Teleoperation</h1>

    <p>
        We use the <a href="https://github.com/Improbable-AI/VisionProTeleop">Apple Vision Pro (AVP)</a> to teleoperate the robot's upper body, which
        provides precise tracking of the human hand, wrist, and head
        poses. The robot uses Relaxed IK to follow these
        poses accurately. We stream the robot's <a href="https://arxiv.org/abs/2407.01512">vision</a> back to
        the AVP. Differing from other works, we enable the waist DoF and gain a more flexible workspace.
    </p>
    <div class="video_container_wrapper1">
        <div class="video_container">
            <video loop autoplay muted playsinline preload="metadata">
                <source src="videos/teleop.mp4" type="video/mp4">
            </video>            
        </div>
    </div> -->


    <!-- <hr class="rounded">

    <h1>Improved 3D Diffusion Policies (iDP3)</h1>

    <p>
        <img src="videos/camera_frame.png" alt="camera" class="image-right" width="35%">
        3D visuomotor policies are inherently dependent on precise camera calibration and fine-grained point cloud segmentation,
        which limits their deployment on mobile platforms such as humanoid robots.
        <br>
        We introduce the <a href="https://humanoid-manipulation.github.io/">Improved 3D Diffusion Policy (iDP3)</a>, a novel 3D visuomotor policy that eliminates these constraints and thus enables its usage on general-purpose robots.
        iDP3 leverages egocentric 3D visual representations, which lie in the camera frame, instead of the world frame as in the <a href="https://3d-diffusion-policy.github.io/">3D Diffusion Policy</a> and other 3D policies. 
        <br>
        Leveraging egocentric 3D visual
    representations presents challenges in eliminating redundant
    point clouds, such as backgrounds or tabletops, especially
    without relying on foundation models. To mitigate this issue, we <i>scale up the vision input</i> to capture the entire scene.
    </p> -->
    
    


    <!-- <h2>Generalization Ability 1: View Generalization</h2>
    <p>
        Our egocentric 3D representations demonstrate impressive view invariance. 
        As shown below, iDP3 consistently grasps objects even under large view changes, while <a href="https://diffusion-policy.cs.columbia.edu/">Diffusion Policy</a> (with finetuned R3M and data augmentation) struggles to grasp even the training objects.
        Diffusion Policy shows occasional success only with minor view changes. Notably, unlike other works to achieve view generalization, we did not incorporate specific designs for equivariance or invariance. 
    </p>
    <div id="video_grid_view" style="padding-top: 1vw; padding-bottom: 2vw">
        <div class="row_label_view">Diffusion Policy
            <br>+Finetuned R3M
            <br>+Augmentation</div>
        <div class="video_wrapper videostyle_with_border">
            <div class="video_container videostyle_with_border_failure">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/view_invariant/dp.mp4" type="video/mp4">
                </video>
                <div class="overlay">DP cannot grasp under large view changes.</div>
            </div>
        </div>
        <div class="row_label_view">iDP3</div>
        <div class="video_wrapper videostyle_with_border">
            <div class="video_container videostyle_with_border_success">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/view_invariant/idp3.mp4" type="video/mp4">
                </video>
                <div class="overlay">iDP3 is robust to large view changes.</div>
            </div>
        </div>
    </div> -->
    <h2>Generalization Ability 2: Object Generalization</h2>
    <p>
        We evaluated several new objects. While Diffusion Policy, due to the use of Color Jitter augmentation, can occasionally handle some unseen objects, it does so with a very low success rate.
        In contrast, iDP3 naturally handles a wide range of objects, thanks to its use of 3D representations.
    </p>
    
    <div id="video_grid_gen" style="padding-top: 1vw; padding-bottom: 2vw">
        <div class="row_label">Diffusion Policy<br>+Finetuned R3M<br>+Augmentation</div>
        <!-- 1 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_failure">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/grasp_origin_dp.mp4" type="video/mp4">
                </video>
                <div class="overlay">Training Scene<br>Training Object & New Object</div>
            </div>
        </div>
        <!-- 3 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_failure">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/pour_old_dp.mp4" type="video/mp4">
                </video>
                <div class="overlay">Training Scene<br>New Object</div>
            </div>
        </div>
    

        <div class="row_label">iDP3</div>
        <!-- 5 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_success">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/grasp_origin_idp3.mp4" type="video/mp4">
                </video>
                <div class="overlay">Training Scene<br>Training Object & New Object</div>
            </div>
        </div>
        <!-- 7 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_success">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/pour_old_idp3.mp4" type="video/mp4">
                </video>
                <div class="overlay">Training Scene<br>New Object</div>
            </div>
        </div>
    </div>

    <h2>Generalization Ability 3: Scene Generalization</h2>
    <p>
        We find that iDP3 generalizes to a wide range of real-world unseen environments, with robust and smooth behavior,
        while Diffusion Policy presents very jittering behavior in the new scene, and even fails to grasp the training object.
    </p>
    
    <div id="video_grid_gen" style="padding-top: 1vw; padding-bottom: 2vw">
        <div class="row_label">Diffusion Policy<br>+Finetuned R3M<br>+Augmentation</div>
         <!-- 2 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_failure">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/grasp_new_dp.mp4" type="video/mp4">
                </video>
                <div class="overlay">New Scene<br>Training Object & New Object</div>
            </div>
        </div>
        <!-- 4 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_failure">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/pour_new_dp.mp4" type="video/mp4">
                </video>
                <div class="overlay">New Scene<br>New Object</div>
            </div>
        </div>
        <div class="row_label">iDP3</div>
        <!-- 6 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_success">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/grasp_new_idp3.mp4" type="video/mp4">
                </video>
                <div class="overlay">New Scene<br>Training Object & New Object</div>
            </div>
        </div>
        <!-- 8 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border_success">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/video_success_failure/pour_new_idp3.mp4" type="video/mp4">
                </video>
                <div class="overlay">New Scene<br>New Object</div>
            </div>
        </div>
    </div>

    <h2>Visualizations of Egocentric 3D Visual Representations</h2>
    <p>
        We visualize our egocentric 3D representations, together with the corresponding images.
        These videos also highlight the complexity of diverse real-world scenes.
        
    </p>
    
    <div id="video_grid_ego" style="padding-top: 1vw; padding-bottom: 2vw">
        <!-- 1 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/grasp1_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pick & Place</div>
            </div>
        </div>
        <!-- 2 -->
        <div class="video_wrapper ">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/pour4_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pour</div>
            </div>
        </div>
        <!-- 3 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/wipe1_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Wipe</div>
            </div>
        </div>
        <!-- 4 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/pour2_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pour</div>
            </div>
        </div>
        <!-- 5 -->
        <div class="video_wrapper ">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/pour3_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pour</div>
            </div>
        </div>
        <!-- 6 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border ">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/wipe4_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Wipe</div>
            </div>
        </div>
        <!-- 7 -->
        <div class="video_wrapper ">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/pour1_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pour</div>
            </div>
        </div>
        <!-- 8 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/wipe3_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Wipe</div>
            </div>
        </div>

        <!-- 9 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/grasp0_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pick & Place</div>
            </div>
        </div>
        <!-- 10 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/grasp2_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pick & Place</div>
            </div>
        </div>
        <!-- 11 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/grasp3_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pick & Place</div>
            </div>
        </div>
        <!-- 12 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/grasp4_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pick & Place</div>
            </div>
        </div>
        <!-- 13 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/pour0_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Pour</div>
            </div>
        </div>
        <!-- 14 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/wipe0_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Wipe</div>
            </div>
        </div>
        <!-- 15 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/wipe2_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Wipe</div>
            </div>
        </div>
        <!-- 6 -->
        <div class="video_wrapper">
            <div class="video_container videostyle_with_border ">
                <video autoplay muted playsinline loop playsinline>
                    <source src="videos/ego_view_vis/wipe4_cropped.mp4" type="video/mp4">
                </video>
                <div class="overlay">Wipe</div>
            </div>
        </div>
    </div>


    <hr class="rounded">

    <h1>Conclusions</h1>

    <p>
        This work presents a real-world imitation learning system that enables a full-sized humanoid robot to generalize practical manipulation skills to diverse real-world environments, trained with data collected solely in one single scene. With more than 2000 rigorous evaluation trials, we present an improved 3D Diffusion Policy, that can learn robustly from human data and perform effectively on our humanoid robot. The results that our humanoid robot can perform autonomous manipulation skills in diverse real-world scenes show the potential of using 3D visuomotor policies in real-world manipulation tasks with data efficiency. 
    </p>

    <h1>Limitations </h1>

    <p>
        (1) Teleoperation with Apple Vision Pro is easy to set up, but it is tiring for human teleoperators, making imitation data hard to scale up within the research lab. 
        <br>(2) The depth sensor still produces noisy and inaccurate point clouds, limiting the performance of iDP3. 
        <br>(3) Collecting fine-grained manipulation skills, such as turning a screw, is time-consuming due to teleoperation with AVP; systems like Aloha~\cite{zhao2023aloha} are easier to collect dexterous manipulation tasks at this stage.
        <br>(4) We avoided using the robot's lower body, as maintaining balance is still challenging due to the hardware constraints brought by current humanoid robots.
        <br>In general, scaling up high-quality manipulation data is the main bottleneck. In the future, we hope to explore how to scale up the training of 3D visuomotor policies with more high-quality data and how to employ our 3D visuomotor policy learning pipeline to humanoid robots with whole-body control.
    </p>



    <h1>BibTeX</h1>
    <p class="bibtex">@article{ze2024humanoid_manipulation,<br>
        &nbsp;&nbsp;title &nbsp;&nbsp;= {Generalizable Humanoid Manipulation with 3D Diffusion Policies},<br>
        &nbsp;&nbsp;author &nbsp;= {Yanjie Ze and Zixuan Chen and Wenhao Wang and Tianyi Chen and Xialin He and Ying Yuan and Xue Bin Peng and Jiajun Wu},<br>
        &nbsp;&nbsp;year &nbsp;&nbsp;&nbsp;= {2024},<br>
        &nbsp;&nbsp;journal = {arXiv preprint arXiv:2410.10803}<br>
        }
    </p>
    <br>
</div>
</body>

<!-- <script src="assets/js/full_screen_video.js"></script> -->
<!-- <script src="assets/js/carousel.js"></script> -->
</html>
